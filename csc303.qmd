---
title: "CSC 303 Finale"
---

```{r}
#| include: false
library(LSTbook)
knitr::opts_chunk$set(
  error = TRUE,
  warning = FALSE,
  message = FALSE
)
set.seed(2020)
```

## Setup

Attach these packages:

```{r eval = FALSE}
library(tidyverse)
library(LSTbook)
```

## Simulation Models


Suppose that some exercise physiologists are researching whether taking a certain vitamin supplement makes people stronger.  Unknown to them, the supplement changes the amount a person can bench-press by:

```{r}
supplement_effect <- 2
```


They do an observational study involving a large number of people:

```{r}
n <- 2000
```

for each person they record whether not the person takes the supplement, and also how much (in pounds) the person can bench-press.  they also happen to record whether the person works out a the Hulk Power Gym or at Planet Fitness.

Here is a simulation-maker for the situation:


```{r}
vitamin_sim <- datasim_make(
  .m <- rnorm(n, mean = 0, sd = 100),
  .w <- bernoulli(n, logodds = .m),
  workout <- ifelse(
    .w == 1,
    "Hulk Power",
    "Planet Fitness"
  ),
  .s <- bernoulli(n, logodds = .m),
  supplement <- ifelse(
    .s == 1,
    "yes",
    "no"
  ),
  bench <- 200 + .m / 5  + supplement_effect * .s + rnorm(n, sd = 10)
)
```

When the statisticians take their sample of individuals, it is like sampling from this "model":

```{r}
vitamin_data <- vitamin_sim %>% 
  take_sample(n = n)
```

Here is a little bit of their sample:

```{r}
#| label: tbl-sample-data
#| tbl-cap: "The first few rows of the sample data."
vitamin_data %>% 
  head(n = 10) %>% 
  knitr::kable()
```

## A Bad Analysis:  Failure to Control

Suppose the statisticians think too simply.  Maybe they make graphs like @fig-vitamin-supplement:

```{r}
#| label: fig-vitamin-supplement
#| fig-cap: "Boxplots of bench-press weight, by supplement use."
vitamin_data %>% 
  ggplot(aes(x = supplement, y = bench)) +
  geom_boxplot(fill = "burlywood")
```

And they make linear models like this one:


```{r}
mod <- lm(
  bench ~ supplement,
  data = vitamin_data
)
summary(mod)
confint(mod)
```

Their work gives the (very wrong) impression that taking vitamins helps a **lot**.

## Confounding Factors and Controlling

The statisticians have found that `supplement` and `bench` are *associated*.  But they really want to know whether `supplement` is part of what *causes* `bench`.

When two variables $X$ and $Y$ are found to be associated, there are three possible explanations for the association:

* $X$ is part of what causes $Y$;
* $Y$ is part of what causes $X$;
* there is a third variable $Z$ that is associated with $X$ and which helps to causes $Y$.

In the third case above, the variable $Z$ is called a *confounding factor*.

The statisticians have recorded the values of `workout`.  They might wonder whether it is a confounding factor.

Well, it is clearly associated with `supplement`, as shown here in @tbl-supplement-workout:

```{r}
#| label: tbl-supplement-workout
#| tbl-cap: "Workout venue, by supplement use."
vitamin_data %>% 
  group_by(supplement, workout) %>% 
  summarize(n = n()) %>% 
  knitr::kable()
```

Also, it is associated with `bench`, as indicated by @fig-bench-workout below:

```{r}
#| label: fig-bench-workout
#| fig-cap: "Boxplots of bench-press weight, by workout venue."
vitamin_data %>% 
  ggplot(aes(x = workout, y = bench)) +
  geom_boxplot(fill = "burlywood")
```

So `workout` is associated with `supplement`, and associated with `bench`.  If it were actually part of what *causes* `bench`, then it would be a confounding factor.

Realizing that `workout` could be a confounding factor, the statisticians decide to control for it, by including it in their visualizations and their models.

For a visualization, they might make something like @fig-obs:

```{r}
#| label: fig-obs
#| fig-cap: "Boxplots of bench-press weight by supplement use, for the two workout venues, in the observational study."
vitamin_data %>% 
  ggplot(aes(x = supplement, y = bench)) +
  geom_boxplot(fill = "burlywood") +
  facet_grid(. ~ workout)
```
With linear models, they control by adding in the possible confounder:

```{r}
mod2 <- lm(bench ~ supplement + workout, data = vitamin_data)
summary(mod2)
confint(mod2)
```

It appears that the supplement still helps, but not by as much as previously thought.


## Experiments are Best

Of course, the statisticians do not know the real situation, which is that:

* `supplement` is a small part of what causes `bench`, but
* motivation-level (`.m`) is a much larger part of what causes `bench`, and
* motivation-level also causes `supplement` (and `workout` too).

This underlying reality is illustrated in the the figure below:

```{r}
dag_draw(vitamin_sim, report_hidden = TRUE)
```


An observational study will miss underlying causal relationships among variables that it does not measure!

In an *experiment*, researchers choose the values of explanatory variables for their subjects.  A good plan for an experiment is to let a chance process determine which subjects take supplements, and which subjects workout at which venue:

```{r}
vitamin_exp <- vitamin_sim %>% 
  datasim_intervene(
    .s <- bernoulli(n, prob = 0.5),
    .w <- bernoulli(n, prob = 0.5)
  )
vitamin_exp_data <- vitamin_exp %>% 
  take_sample(n = n, report_hidden = TRUE)
```

Now `supplement` and `workout` are no longer associated, as seen in @tbl-supplement-workout-exp below

```{r}
#| label: tbl-supplement-workout-exp
#| tbl-cap: "Workout venue by supplement use, in the randomized experiment."
vitamin_exp_data %>% 
  group_by(supplement, workout) %>% 
  summarize(n = n()) %>% 
  knitr::kable()
```

A visualization based on the experiment is shown in @fig-exp:

```{r}
#| label: fig-exp
#| fig-cap: "Boxplots of bench-press weight by supplement use, for the two workout venues, in the experiment."
vitamin_exp_data %>% 
  ggplot(aes(x = supplement, y = bench)) +
  geom_boxplot(fill = "burlywood") +
  facet_grid(. ~ workout)
```

Linear models now give a more accurate assessment of the effect of `supplement`:

```{r}
mod3 <- lm(bench ~ supplement + workout, data = vitamin_exp_data)
summary(mod3)
confint(mod3)
```

Why does this work?  It's because the experiment broke the connection between the lurking variable motivation-level (`.m`) and the explanatory variables in the study, as shown in @fig-motivation

```{r}
#| label: fig-motivation
#| fig-cap: "Motivation-level, for each of the treatment groups in the experiment."
vitamin_exp_data %>% 
  ggplot(aes(x = supplement, y = .m)) +
  geom_violin(fill = "burlywood") +
  geom_jitter(width = 0.25, size = 0.1) +
  facet_grid(. ~ workout) +
  labs(y = "motivation-level")
```

This is further illustrated by the following diagram:

```{r}
dag_draw(vitamin_exp, report_hidden = TRUE)
```


Any statistically-significant differences in bench-press weight between the groups can now be attributed to the supplement.

Note that the actually impact of `supplement` on `bench` is so small that a much larger experiment would be required, in order to be sure of detecting the impact:

```{r}
vitamin_exp_data_2 <- vitamin_exp %>% 
  take_sample(n = 10000)
mod4 <- lm(bench ~ supplement + workout, data = vitamin_exp_data_2)
summary(mod4)
confint(mod4)
```


